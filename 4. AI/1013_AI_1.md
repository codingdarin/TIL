# AI, ML, DL 기초 학습

## 1. AI, ML, DL의 정의 및 관계

### AI (Artificial Intelligence, 인공지능)
- 주어진 환경/데이터를 인지하고 학습, 추론을 통해 목표 달성을 하도록 예측, 행동, 선택을 계획하는 시스템
- 가장 넓은 개념

### ML (Machine Learning, 머신러닝)
- AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 컴퓨터 알고리즘
- 예: 언어 모델, 이미지 분류 모델, 추천 시스템

### DL (Deep Learning, 딥러닝)
- ML 범주 내에서 신경망(Neural Network)을 사용한 학습 방법론

### 관계도
```
AI (가장 넓음)
 └─ ML (AI의 부분집합)
     └─ DL (ML의 부분집합)
```

### AI - ML의 경계
- ML이 아닌 AI 시스템: 규칙 기반 시스템, 휴리스틱 기반 (최적화) 알고리즘

---

## 2. 데이터와 학습의 이해

### 데이터 구성요소

#### Feature (피처, 특성)
- 모델이 예측에 사용하는 입력 정보
- 예측, 판단의 근거/단서
- 예시:
  - 유튜브 스팸 분류: 댓글 제목, 발신자, 단어 빈도
  - 이미지 분류: 각 영상들의 정보(정도, 크기/메타, 조화수, 좋아요 수 등), 사용자 정보(시청 이력, 구독 채널 등)

#### Label (라벨, 목표값)
- 모델이 예측하려는 정답
- 학습의 목표값
- 예시:
  - 유튜브 스팸 분류: 시청 여부, 좋아요 클릭 여부
  - 이미지 분류: 스팸 / 정상

### ML 실생활 예시

#### 예시 1 - 유튜브 추천
- Feature: 각 영상들의 정보(제목, 크리에이터, 조회수, 좋아요 수 등), 사용자 정보(시청 이력, 구독 채널 등)
- Label: 영상에 대한 사용자 피드백(시청 여부, 좋아요 클릭 여부)

#### 예시 2 - 스팸메일 분류
- Feature: 메일 제목, 발신자, 단어 빈도
- Label: 스팸 / 정상

---

## 3. 단일 피처 기반 학습

### 1D 피처 기반 학습이란?
- 1D = 1차원
- Feature가 하나일 때 머신러닝이 학습하는 가장 단순한 형태

### 수식 표현
```
Income_i = f*(Years of Education_i) + ε_i
```

- 데이터셋 D: 30명의 Years of Education (피처)와 Income (라벨) 쌍
- D = {(Years of Education_i, Income_i)}^30_{i=1}

### 구성 요소

#### 미지의 참 함수 (f*)
- Feature와 Label 사이의 실제 관계
- 데이터에는 주로 측정 오차가 섞여 있음
- 하지만 직접 관측할 수 없음
- 모차가 포함된 데이터(점)만 관측 가능

#### 측정 오차 (ε)
- 데이터에는 추정 측정 오차가 섞여 있음
- 원인: 측정 기기의 한계, 환경적 요인 등
- 따라서, 데이터 = 참 함수 + 오차 (f* + ε)

### 학습 목표
- 피처와 라벨의 관계를 잘 나타내는 함수 f 무엇일까?

---

## 4. 모델과 가설 공간

### 학습 (Learning)
- "입력(Feature) → 출력(Label)" 관계를 찾는 과정
- 정답 관계를 하나씩 암수로 표현함
- 하지만 관계를 표현할 수 있는 함수는 무수히 많음

### 가설공간 (Hypothesis Space)
- 관계를 표현할 수 있는 모든 후보 함수들의 모음
- 피처 공간과 라벨 공간에서 정의된 함수들의 집합

### 모델 (Model)
- 가설공간 중에 속한 특정 함수 f

### 가설공간의 종류

#### 선형함수 가설공간
- 무수히 많은 선형 함수의 집합
- 단순한 표현

#### 비선형함수 가설공간
- 특정 선형 함수의 집합보다 더 복잡한 오차가 섞여 있음
- 데이터에는 주로 측정 오차가 섞여 있음

### 함수 선택 기준
- 데이터를 설명하는 여러 함수 후보가 존재
- 어떤 함수가 가장 잘 맞는지 학습해야 함

---

## 5. 학습이란

### 정의
- 주어진 데이터와 성능측도를 바탕으로 가설공간에서 **최적의 모델**을 선택하는 과정

### 학습 프로세스
```
데이터 D → 가설공간 → 선택된 모델 f
```

1. **학습 전**: 데이터 분포만 관측됨
2. **가설공간**: 선형함수 가설공간 또는 비선형함수 가설공간에서 여러 함수 후보 존재
3. **학습 후**: 최적의 함수를 선택하여 데이터를 가장 잘 설명하는 모델 생성

---

## 6. 복수 피처 기반 학습

### 2D 피처 기반 학습

#### 1D에서 2D로 확장
```
Income = f*(Years of Education, Seniority) + ε
```

#### 주요 변화
- **1D**: 피처가 1개 → 그래프는 선(line)
- **2D**: 피처가 2개 → 그래프는 **면(Surface)**

#### 학습 대상
- 파란색 Surface = 미지의 참 함수 f*는 관측 불가능
- 빨간색 점 = 데이터만 관측 가능함

#### 학습 목표
- 어떤 가설공간을 사용할까?
- 데이터를 활용하여 어떤 모델 f를 선택해야 할까?

### 2D에서의 가설공간

#### 선형함수 가설공간
- 평평한 평면(plane)으로만 표현
- 데이터와 모델이 다소 떨어져 있음
- 단순하지만 복잡한 관계 표현 못함

#### 비선형함수 가설공간
- 휘어진 곡면(curved surface)으로 표현
- 더 복잡한 관계 표현 가능
- 데이터에 더 가깝게 fitting 됨

---

## 7. 일반적 용어 정리 및 모델 가정

### 표기법 통일

#### 기존 표현
```
Income = f*(Years of Education, Seniority, ...) + ε
```

#### 일반화 표현
```
Y = f*(X) + ε
```

### 각 요소의 의미

- **Y**: 우리가 예측하려는 라벨(반응/목표) 변수
  - Income을 Y로 표기

- **X₁**: 첫번째 피처(입력/예측) 변수
  - Years of Education을 X₁로 표기

- **X₂**: 두번째 피처(입력/예측) 변수
  - Seniority를 X₂로 표기

- **다른 변수**: 피처가 여러 개면 X₃, X₄, ... 계속 확장 가능

### 피처 벡터 표현

#### 일반적인 p차원 피처
피처가 p개일 때:
```
X = [X₁]
    [X₂]  ∈ ℝᵖ
    [⋮ ]
    [Xₚ]
```

#### 모델 함수형
```
f*: ℝᵖ → ℝ
Y = f*(X) + ε
```

- f*는 p차원 실수 공간(ℝᵖ)에서 1차원 실수(ℝ)로 매핑하는 함수
- **측정오차 ε**: 피처 X와 독립, 평균 E[ε] = 0로 가정

---

## 8. 왜 f(·)를 학습하는가?

### 예측 (Prediction)
- 잘 학습된 f가 있으면, 새로운 입력 X = x에서 반응/목표 Y를 예측할 수 있음

### 중요 특성 파악 (Feature Importance)
- 피처들 X = (X₁, X₂, ..., Xₚ)이 어떤 특성이 Y를 설명하는데 **중요**한지, 어떤 것은 **덜 중요(무관)**한지 알 수 없음
- 예: 근속연수(Seniority), 교육기간(Years of Education)은 소득(Income)에 영향을 줄 수 있지만, 혼인 여부(Marital Status)는 영향이 거의 없을 것임

### 해석 가능성 (Interpretability)
- f의 **복잡도**에 따라 각 구성요소 Xⱼ가 Y에 **어떻게 영향**을 미치는지 (증가/감소 방향, 민감도 등) 이해할 수 있음

---

## 핵심 정리

- **1D → 2D → 일반 p차원**으로 확장 가능
- 피처가 많아져도 개념은 동일: 데이터로부터 최적의 함수 f 찾기
- **f를 학습하는 이유**: 예측 + 중요 변수 파악 + 해석

---

# 지도학습 개념

## 학습 목표
- 회귀(연속값)와 분류(범주값)의 문제 정의와 출력 차이 이해
- 문제 유형에 맞는 오류/평가지표를 바르게 선택, 해석
- 학습의 목적: 테스트 성능 최대화(테스트 오류 최소화)에 대한 이해
- 오버피팅(overfitting)의 이해

---

## 0. 학습 시작

### 지도학습의 목표
> "훈련 데이터(이)가 아니라, 처음 보는 데이터에서의 예측 성능 향상"

- 지도학습은 입력 + 정답(레이블)을 가지고 예측 규칙을 배우는 방법
- 이미 갖고 있는 데이터를 활용하여 학습하지만, 궁극적으로 새로운 데이터에서의 예측을 잘 하고자 하는데 초점
- 예: 어제까지 고객 데이터로 "내일 이탈할 고객" 미리 알기, 기존 거래 사기(Fraud) 데이터로 새로운 사기 탐지

### 프로세스
1. 훈련 데이터로 모델 학습
2. 새로운 데이터에 적용
3. 예측 결과 도출

---

## 1. 지도학습(supervised learning)이란?

### 데이터
- 입력(특성)과 정답(라벨)이 쌍으로 있는 데이터

### 목표
- 새 입력이 들어오면 정답을 잘 맞추는 규칙을 학습

### 지도학습의 종류

#### 회귀(Regression)
- 예측값이 숫자(가격, 점수, 온도)

#### 분류(Classification)
- 예측값이 범주(스팸/정상, 질병 유/무)

---

## 2. 지도학습 용어

### 특성 (Feature, x)
- 예측에 쓰는 설명 변수
- 예: 집값 예측 (지역, 평수, 방수, 연식), 이메일 스팸 필터링 (제목, 내용 텍스트, 송신인)

### 라벨 (Label, y)
- 맞춰야 하는 정답
- 예: 집값, 스팸/정상이메일

### 예측값 (ŷ)
- 모델이 내놓은 결과(숫자 또는 범주)

### 오류 (Error)
- 예측값(ŷ)과 라벨(y)의 차이: ŷ - y

---

## 3. 회귀(Regression) 문제

### 정의
- 언제로부터 숫자를 얼마나 정확히 예측할까?

### 예시
- Feature: 면적, 방수, 연식 → Label: 집값(원 단위)
- Feature: 매체별 광고비(TV/라디오/온라인) → Label: 매출액

### 라벨 및 예측 모델의 출력
- 연속적인 수치

---

## 4. 회귀 오류: 평균제곱오차(MSE)

### 평균제곱오차(Mean Squared Error)

#### 정의
각 데이터에서 정답(yᵢ)과 예측(ŷᵢ)의 평균 제곱 차이값

```
MSE = (1/n) Σ(yᵢ - ŷᵢ)²
```

#### 해석
큰 오류를 더 크게 벌주므로, 전체 오류 수준을 한눈에 봄

### RMSE (Root Mean Squared Error)

데이터와 같은 단위를 쓰고 싶으면 RMSE(MSE의 제곱근)도 사용

```
RMSE = √MSE = √[(1/n) Σ(yᵢ - ŷᵢ)²]
```

---

## 5. 회귀 설명력: R² (결정계수)

### 결정계수

#### 정의
- 라벨의 분산 중에서 특성으로 설명되는 비율
- "평균만 쓰는 단순한 예측보다 더 잘 맞추는지를 0~1 사이로 나타낸 값"

```
R² = 1 - [Σ(yᵢ - ŷᵢ)²] / [Σ(yᵢ - ȳ)²]
```
- ȳ = yᵢ들의 평균값

#### 해석
1에 가까울수록 설명력이 높고, 낮을수록 설명력이 낮음

#### 결론
R²가 클수가 나를 수 있을까? 나를 수 있음. 예측값(ŷᵢ)들이 평균값 ȳ보다도 못한다면 음수가 될 수 있음

---

## 6. 분류(Classification) 문제

### 정의
- 언제로부터 범주는 얼마나 정확히 가려낼까?

### 예시
- Feature: 메일 내용, 보낸이 이메일주소 → Label: 스팸/정상
- Feature: 종양 변경, 면적 → Label: 악성/양성

### 라벨
- 범주 라벨(이진/다중)

---

## 7. 분류 정확도(Accuracy)

### 정확도

#### 정의
전체 중 맞춘 비율

```
Accuracy = (1/n) Σ 𝟙(yᵢ = ŷᵢ)
```
- 𝟙: 지시(indicator) 함수
- 𝟙(A) = 1 if A true

### 정확도만 보면 발생하는 문제
불균형 데이터(양성 1%, 음성 99%)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있음

### 결론
정확도만 보지 말고 다른 지표도 함께 봐야 안전

---

## 8. 혼동행렬(Confusion Matrix)

### 혼동행렬

#### 정의
예측과 실제 각 사이의 관계를 행렬 형태로 표현

#### 구성요소

- **TP (True Positive)**: 실제 양성, 예측도 양성
- **TN (True Negative)**: 실제 음성, 예측도 음성
- **FP (False Positive)**: 실제는 음성인데 양성이라 함 (오탐)
- **FN (False Negative)**: 실제는 양성인데 음성이라 함 (누락)

### 정밀도(Precision)
"양성이라 판정한 것 중 진짜 양성의 비율"

```
Precision = TP / (TP + FP)
```

### 재현율(Sensitivity or Recall)
"진짜 양성 가운데 잡아낸 예측 양성 비율"

```
Recall = TP / (TP + FN)
```

### F1-score
정밀도와 재현율의 조화평균

```
F1 = 2 × (정밀도 × 재현율) / (정밀도 + 재현율)
```

---

## 9. 학습의 목적

### 학습의 목적은 테스트 예측(일반화)

- 학습 모델의 성능 평가는 모델이 처음 보는(학습에 사용되지 않은) 데이터로 평가
- **일반화(generalization)**: 오류의 최소화 지향

### 중요성
- 훈련 데이터에서 성능이 아무리 좋아도, 새로운 데이터에서 성능이 떨어지면 실전엔 사용할 수 없음
- 다음 차시(3차시)에서 일반화 성능을 추정(검증/교차검증)하는 방법을 배울 예정

---

## 10. 오버피팅(overfitting)이란?

### 오버피팅(overfitting)

#### 정의
- 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 훈련에서는 성능이 좋지만 테스트에서는 나빠지는 현상
- 현상: 훈련 오류 급격히 낮춤, 테스트 오류 높음/요동

### 오버피팅이 왜 안 좋은가?

#### 표본(sample) 의존 불안정
- 훈련 데이터는 모집단의 일부
- 표본이라 우연한 잡음이 섞임. 이것에만 과하게 맞추어 합치하면 실물 잘 개만 바뀌어도 예측이 크게 흔들림(분산 ↑)

#### 일반화 실패
- 보지 못한 데이터(테스트) 오류가 커짐. 모(population)집단 성능과 격차가 벌어짐

---

## 11. 오버피팅에 대한 오해

### 오버피팅 ≠ 분포 변화(distribution shift)와 인한 에러 증가

#### 분포 변화로 인한 오류
- 훈련 데이터 분포와 테스트 분포가 다름으로 (환경·개념·센서 변경 등) 성능이 떨어지는 현상

#### 분포 변화로 인한 에러 증가는 모델이 과적합하지 않아도 발생 가능

#### 예시
- 훈련 데이터: 실제 고양이/개 사진
- 테스트 데이터: 일러스트 고양이/개 그림
- 분포가 달라서 성능 저하

---

## 12. 오버피팅 vs 언더피팅

### 오버피팅 vs 언더피팅 (교집 장기)

#### 오버피팅
- 모델이 너무 복잡
- 잡음까지 학습 (테스트 성능 나쁨)

#### 언더피팅
- 모델이 단순하거나 학습이 완료되지 않음
- 중요한 패턴을 놓침 (오류 큼)

### 해결 실마리
더 많은 데이터, 테스트 데이터를 활용한 모델 선정, 교차 검증(3차시)

### 그래프 비교

#### 분류 예시
- **Overfitting**: 너무 복잡한 경계선
- **Right Fit**: 적절한 경계선
- **Underfitting**: 너무 단순한 경계선

#### 회귀 예시
- **Overfitting**: 너무 구불구불한 곡선
- **Right Fit**: 적절한 곡선
- **Underfitting**: 너무 단순한 직선

---

## 지도학습 핵심 정리

- **회귀**: 연속적인 숫자 예측 (MSE, RMSE, R² 사용)
- **분류**: 범주 예측 (Accuracy, Precision, Recall, F1-score 사용)
- **학습 목표**: 테스트 데이터에서의 성능 최대화 (일반화)
- **오버피팅**: 훈련 데이터에 과적합되어 테스트 성능 저하
- **언더피팅**: 모델이 너무 단순하여 패턴을 제대로 학습하지 못함